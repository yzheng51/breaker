2024-02-14 18:43:27,536 - - - INFO - #params: 73444
2024-02-14 18:43:27,536 - - - INFO - param:{'tower_layers': [32, 10, 1], 'embedding_dim': 10, 'n_cluster': 4, 'learning_rate': 0.001, 'cluster_alpha': 0.1, 'encode_dims': [256, 64], 'epochs': 8, 'batch_size': 128, 'alpha': 1, 'earlystop_patience': 1, 'target_cycle': 6}
2024-02-14 18:43:27,690 - - - INFO - Kmeans train start.
2024-02-14 18:43:28,131 - - - INFO - Kmeans train end.
2024-02-14 18:43:28,192 - - - INFO - train learning_phase:1
2024-02-14 18:43:28,590 - - - INFO - [0]Train loss on step 0: 0.694642, logloss: 0.694642, clustloss: 0.000000 [use time per iter:0.398]
2024-02-14 18:43:28,590 - - - INFO - [0.24999458 0.24993931 0.25003868 0.25002787]
2024-02-14 18:43:28,592 - - - INFO - [0.249989   0.24992976 0.25007203 0.25000912]
2024-02-14 18:43:28,594 - - - INFO - Counter({2: 68, 1: 22, 0: 20, 3: 18})
2024-02-14 18:43:29,650 - - - INFO - [6400]Train loss on step 50: 0.268974, logloss: 0.268971, clustloss: 0.000026 [use time per iter:0.029]
2024-02-14 18:43:29,650 - - - INFO - [0.25824112 0.25807965 0.24242875 0.24125057]
2024-02-14 18:43:29,651 - - - INFO - [0.2582283  0.25806025 0.24247189 0.24123956]
2024-02-14 18:43:29,651 - - - INFO - Counter({0: 128})
2024-02-14 18:43:30,894 - - - INFO - train learning_phase:1
2024-02-14 18:43:31,113 - - - INFO - [0]Train loss on step 0: 0.226833, logloss: 0.226831, clustloss: 0.000021 [use time per iter:0.046]
2024-02-14 18:43:31,114 - - - INFO - [0.2590451  0.2587577  0.24135211 0.240845  ]
2024-02-14 18:43:31,115 - - - INFO - [0.25906292 0.25876012 0.24134834 0.24082902]
2024-02-14 18:43:31,115 - - - INFO - Counter({0: 128})
2024-02-14 18:43:32,317 - - - INFO - [6400]Train loss on step 50: 0.139102, logloss: 0.139101, clustloss: 0.000012 [use time per iter:0.037]
2024-02-14 18:43:32,317 - - - INFO - [0.26035196 0.25994584 0.23990218 0.23979962]
2024-02-14 18:43:32,317 - - - INFO - [0.26030973 0.2599205  0.24000667 0.23976295]
2024-02-14 18:43:32,317 - - - INFO - Counter({0: 128})
